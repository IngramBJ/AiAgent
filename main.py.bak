import os, requests, re
from fastapi import FastAPI, BackgroundTasks, Response, Header, HTTPException
from pydantic import BaseModel
from typing import List, Optional, AsyncGenerator
from contextlib import asynccontextmanager
from dotenv import load_dotenv

from langchain_community.chat_models.dashscope import Tongyi
from langchain_community.embeddings import DashScopeEmbeddings
from langchain_chroma import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.schema import Document

# 全局变量
llm: Tongyi
emb: DashScopeEmbeddings
text_splitter: RecursiveCharacterTextSplitter

@asynccontextmanager
async def lifespan(app: FastAPI) -> AsyncGenerator:
    global llm, emb, text_splitter
    print("Pre-loading models...")
    load_dotenv()

    # 使用阿里云通义千问作为对话模型
    llm = Tongyi(
        model_name=os.getenv("DASHSCOPE_MODEL", "qwen-max"),
        dashscope_api_key=os.getenv("DASHSCOPE_API_KEY"),
        temperature=0.2,
    )
    # 使用阿里云通义千问作为嵌入模型
    emb = DashScopeEmbeddings(
        model="text-embedding-v2",
        dashscope_api_key=os.getenv("DASHSCOPE_API_KEY")
    )

    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    print("Models pre-loaded.")
    yield

app = FastAPI(title="LangChain+Coze Agent Backend", lifespan=lifespan)
app.add_middleware(
    CORSMiddleware, allow_origins=["*"], allow_credentials=True,
    allow_methods=["*"], allow_headers=["*"],
)

# 环境变量与配置
GITHUB_TOKEN  = os.getenv("GITHUB_TOKEN")
BACKEND_TOKEN = os.getenv("BACKEND_TOKEN", "")
ALLOW_EXT = {"kt","java","xml","md","txt","yml","yaml","json","gradle","tex","cls","sty"}
CHROMA_DIR = os.path.abspath("./storage/chroma")
os.makedirs(CHROMA_DIR, exist_ok=True)

def auth_or_403(token: str):
    if not BACKEND_TOKEN: return
    if token != f"Bearer {BACKEND_TOKEN}" and token != BACKEND_TOKEN:
        raise HTTPException(status_code=403, detail="Invalid backend token")

def parse_repo(url: str):
    m = re.match(r"https?://github\.com/([^/]+)/([^/]+)(/.*)?", url.strip())
    if not m: raise ValueError("repo_url 需形如 https://github.com/owner/repo")
    owner, repo, extra = m.group(1), m.group(2), m.group(3) or ""
    subdir = extra.strip("/").split("/",2)[-1] if extra.strip("/") else ""
    return owner, repo, subdir

def get_default_branch(owner, repo, token=None):
    url = f"https://api.github.com/repos/{owner}/{repo}"
    headers = {"Accept":"application/vnd.github+json"}
    if token: headers["Authorization"]=f"Bearer {token}"
    try:
        r = requests.get(url, headers=headers, timeout=15)
        r.raise_for_status()
        return r.json().get("default_branch", "main")
    except:
        return "main"

def get_tree(owner, repo, branch, token=None):
    url = f"https://api.github.com/repos/{owner}/{repo}/git/trees/{branch}?recursive=1"
    headers = {"Accept":"application/vnd.github+json"}
    if token: headers["Authorization"]=f"Bearer {token}"
    try:
        r = requests.get(url, headers=headers, timeout=30)
        r.raise_for_status()
        data = r.json()
        if "tree" not in data: raise ValueError("获取文件树失败")
        return data.get("tree", [])
    except requests.exceptions.RequestException as e:
        raise ValueError(f"访问 GitHub API 失败 (branch='{branch}'): {e}")

def filter_paths(tree, include_ext, subdir, max_files):
    files=[]
    subdir = subdir.strip("/") if subdir else ""
    for it in tree:
        if it.get("type")!="blob": continue
        p = it.get("path","")
        if subdir and not p.startswith(subdir + "/"): continue
        ext = p.split(".")[-1].lower() if "." in p else ""
        if include_ext and ext not in include_ext: continue
        size = it.get("size", 0)
        if isinstance(size,int) and size>1_200_000: continue
        files.append(p)
        if len(files)>=max_files: break
    return files

def fetch_raw(owner, repo, branch, path, token=None):
    raw = f"https://raw.githubusercontent.com/{owner}/{repo}/{branch}/{path}"
    headers={}
    if token: headers["Authorization"]=f"Bearer {token}"
    r = requests.get(raw, headers=headers, timeout=30)
    if r.status_code==404: return ""
    r.raise_for_status()
    return r.text

def get_vectorstore(user_id:str):
    safe_name = re.sub(r'[^a-zA-Z0-9._-]', '_', user_id)
    if not safe_name or not safe_name[0].isalnum(): safe_name="c_"+safe_name
    if len(safe_name)<3: safe_name=safe_name.ljust(3,'0')
    if len(safe_name)>63: safe_name=safe_name[:63]
    if safe_name.endswith(('_','.')): safe_name=safe_name[:-1]+'0'
    return Chroma(collection_name=safe_name, embedding_function=emb, persist_directory=CHROMA_DIR)

def build_sys_prompt(memo: str):
    base = """你是开发辅助智能体。必须遵守：
- 优先基于检索到的片段与用户上传的文件回答，并在答案末尾列出引用的“文件路径:行号”。
- 当用户提出“修复/修改/重构/补丁”请求，请输出：
  1) 变更计划（条目说明：在哪个文件、哪个方法、做什么改动）
  2) 补丁内容（统一 diff 格式），用 ```diff 包裹
- 信息不足时，明确指出需要补充的文件/模块/路径。
- 回答结构：
  1) 直接答案
  2) 变更计划（如涉及代码修改）
  3) 补丁（如需要）
  4) 引用（文件:行号）
  5) 下一步建议
"""
    if memo.strip():
        base += f"\n（该用户的长期记忆）：\n{memo}\n"
    return base

class ImportRequest(BaseModel):
    repo_url: str; branch: Optional[str] = ""; subdir: Optional[str] = ""
    token: Optional[str] = None; include_ext: Optional[str] = None
    max_files: Optional[int] = 800; user_id: str

class AskRequest(BaseModel):
    question: str; user_id: str

def import_repo_task(req: ImportRequest):
    print(f"[BG Task] Starting import for {req.user_id}: {req.repo_url}")
    try:
        owner, repo, subdir0 = parse_repo(req.repo_url)
        token = req.token or GITHUB_TOKEN or None
        branch_to_use = req.branch or get_default_branch(owner, repo, token)
        subdir = req.subdir or subdir0
        include = set((req.include_ext or ",".join(ALLOW_EXT)).split(","))
        
        print(f"[BG Task] Fetching file tree for {owner}/{repo}@{branch_to_use}...")
        tree = get_tree(owner, repo, branch_to_use, token)
        paths = filter_paths(tree, include, subdir, req.max_files or 800)
        print(f"[BG Task] Found {len(paths)} files to import.")
        
        docs=[]
        for i, p in enumerate(paths):
            if i % 20 == 0: print(f"[BG Task] Processing file {i+1}/{len(paths)}: {p}")
            try:
                txt = fetch_raw(owner, repo, branch_to_use, p, token)
                if txt.strip():
                    for chunk in text_splitter.split_text(txt):
                        docs.append(Document(page_content=chunk, metadata={"repo":f"{owner}/{repo}","branch":branch_to_use,"path":p}))
            except: continue
        
        print(f"[BG Task] Embedding {len(docs)} chunks...")
        vs = get_vectorstore(req.user_id)
        if docs:
            vs.add_documents(docs); vs.persist()
        
        print(f"[BG Task] Import completed for {req.user_id}.")
    except Exception as e:
        print(f"[BG Task] ERROR during import for {req.user_id}: {e}")

@app.get("/health")
def health(): return {"ok": True}

@app.post("/import")
def import_repo(req: ImportRequest, background_tasks: BackgroundTasks, authorization: Optional[str]=Header(None)):
    auth_or_403(authorization or "")
    background_tasks.add_task(import_repo_task, req)
    return Response(
        status_code=202,
        content='{"message": "Import job started in background. Please wait a moment before asking questions."}',
        media_type="application/json"
    )

@app.post("/ask")
def ask_code(req: AskRequest, authorization: Optional[str]=Header(None)):
    auth_or_403(authorization or "")
    try:
        vs = get_vectorstore(req.user_id)
        retriever = vs.as_retriever(search_kwargs={"k": 6})
        rel_docs = retriever.get_relevant_documents(req.question)
        citations = [f"{d.metadata.get('repo','')}/{d.metadata.get('path','')}" for d in rel_docs if d.metadata]
        if not rel_docs:
            snippet = "(未检索到相关片段)"
            citations_text = "(无引用)"
        else:
            citations_text = "\n".join(f"- {c}" for c in citations)
            snippet = "\n\n".join([f"==== {c} ====\n{d.page_content[:800]}" for c, d in zip(citations, rel_docs)])
        
        sys_prompt = build_sys_prompt("")
        messages = [
            {"role":"system","content": sys_prompt},
            {"role":"user","content": f"问题：{req.question}\n\n相关片段（供参考）：\n{snippet}\n\n引用：\n{citations_text}"}
        ]
        resp = llm.invoke(messages)
        return {"answer": resp.content, "citations": citations}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"后端处理/ask时异常: {e}")
